volumes:
  database_data:
  prometheus:
services:
  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/host.access.log:/var/log/nginx/host.access.log
    depends_on:
      gold-price:
        condition: service_started
      rate-exchange:
        condition: service_started
      fluentd:
        condition: service_started
      grafana:
        condition: service_started
    healthcheck:
      test: ["CMD", "service", "nginx", "status", "||", "exit", "1"]
      start_period: 30s
      timeout: 5s
      retries: 5
      interval: 1m

  gold-price:
    build: ./gold-price
    image: gold-price/gold-price-vn:1.2.1
    container_name: gold-price
    environment:
      - DB_HOST=database
      - DB_PORT=5432
      - DB_NAME=statistic_log
      - DB_USER=postgres
      - DB_PASSWORD=ppaasssswwoorrdd
    expose:
      - "8000"
    depends_on:
      database:
        condition: service_healthy
    volumes:
      - ./gold-price:/app

  rate-exchange:
    build: ./rate-exchange
    image: rate-exchange/rate-exchange-vnd:1.1.0
    container_name: rate-exchange
    environment:
      - DB_HOST=database
      - DB_PORT=5432
      - DB_NAME=statistic_log
      - DB_USER=postgres
      - DB_PASSWORD=ppaasssswwoorrdd
    expose:
      - "8000"
    depends_on:
      database:
        condition: service_healthy
    volumes:
      - ./rate-exchange:/app
  
  database:
    image: postgres:latest
    container_name: postgres_database
    user: postgres
    environment:
      - POSTGRES_PASSWORD=ppaasssswwoorrdd
    expose:
      - "5432"
    volumes:
      - ./init_postgres.sql:/docker-entrypoint-initdb.d/init_postgres.sql
      - database_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready", "-d", "db_prod"]
      start_period: 10s
      timeout: 5s
      retries: 5
      interval: 60s
  
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus:/etc/prometheus/
      - prometheus:/prometheus
    ports:
      - 9090:9090
    command: 
      - --config.file=/etc/prometheus/prometheus.yml
      - '--storage.tsdb.path=/prometheus'
      - --query.lookback-delta=100m
    depends_on:
      cadvisor:
        condition: service_started
      node-exporter:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--spider", "--timeout=10", "http://localhost:9090"]
      start_period: 10s
      timeout: 5s
      retries: 5
      interval: 30s

#TODO: where and how to save historical data for retrieve at times when servers supposed to down
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    user: root
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=grafana
    volumes:
      - ./grafana/dashboard.yaml:/etc/grafana/provisioning/dashboards/main.yaml
      - ./grafana/datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
      - ./grafana/dashboards:/var/lib/grafana/dashboards
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini
    depends_on:
      prometheus:
        condition: service_healthy
      database:
        condition: service_healthy
    ports:
      - 3000:3000
    command:
      - "grafana cli plugins install marcusolsson-json-datasource"
      - --config=/etc/grafana/grafana.ini
    healthcheck:
      test: ["CMD", "wget", "--spider", "--timeout=10", "http://localhost:3000/api/health"]
      start_period: 1m
      timeout: 30s
      retries: 5
      interval: 1m

  nginx-prometheus-exporter:
    image: nginx/nginx-prometheus-exporter:latest
    container_name: nginx-prometheus-exporter
    ports: 
      - 9113:9113
    command: 
      - --nginx.scrape-uri=http://nginx:80/stub_status
      
  fluentd:
    build: ./fluentd
    container_name: fluentd
    ports: 
      - "24231:24231"
    volumes:
      - ./fluentd/fluent.conf:/etc/fluent/fluent.conf
      - ./nginx/host.access.log:/var/log/nginx/access.log
    command: 
      - --config=/etc/fluent/fluent.conf

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      # - /dev/disk/:/dev/disk:ro
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD", "wget", "--spider", "--timeout=10", "http://localhost:8080"]
      start_period: 30s
      timeout: 5s
      retries: 5
      interval: 1m

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    volumes:
      - ./node-exporter:/etc/nodeexporter
    command: 
      - '--path.rootfs=/etc/nodeexporter'
    expose:
      - 9100:9100
    healthcheck:
      test: ["CMD", "wget", "--spider", "--timeout=10", "http://localhost:9100/metrics"]
      start_period: 30s
      timeout: 5s
      retries: 5
      interval: 1m
  
  front-end:
    build: ./frontend
    image: front-end/health-monitoring:1.0.0
    container_name: front-end
    expose:
      - "3000"

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    depends_on:
      - prometheus
    ports:
      - 9093:9093
    volumes:
      - ./alertmanager:/etc/alertmanager
    command:
      - --config.file=/etc/alertmanager/alertmanager.yml
  
  # stress-test:
  #   image: polinux/stress:latest
  #   container_name: stress-test
  #   command:
        # docker run -ti --rm polinux/stress stress --cpu 1 --io 1 --vm 1 --vm-bytes 128M --timeout 180s --verbose  